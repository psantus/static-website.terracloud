Cloud 101 - Episode 3 : 7 clÃ©s pour Ã©viter le gÃ¢chis !ğŸ’° #FinOps

## Cloud 101 - Episode 3 : 7 clÃ©s pour Ã©viter le gÃ¢chis !ğŸ’° #FinOps

## Blague rÃ©currente entre ingÃ©nieurs cloud : Â« ce qui coÃ»te cher sur le cloud, ce n'est pas tant les ressources qu'on utilise que celles qu'on a oubliÃ© d'Ã©teindre Â». Lors d'une mission rÃ©cente, cet adage s'est encore vÃ©rifiÃ©, puisque j'ai pu identifier en quelques heures plus de $20k d'Ã©conomies mensuelles pour mon client (oui, parfois, on devrait nÃ©gocier un intÃ©ressement).Dans cet article, je vous partage quelques bonnes pratiques FinOps pour Ã©viter le gÃ¢chis.

## 1. Une conscience partagÃ©e des coÃ»ts

Dans une infrastructure autogÃ©rÃ©e, lâ€™essentiel des coÃ»ts est subi au moment de lâ€™investissement (en gÃ©nÃ©ral avec un coefficient de sÃ©curitÃ© important), aprÃ¨s quoi viennent les coÃ»ts humains (directs, ou via les contrats de support). On contrÃ´le donc finement (parfois Ã  lâ€™excÃ¨s) le temps passÃ© sur chaque activitÃ©, et on ne regarde pas Ã  la dÃ©pense concernant lâ€™infra consommÃ©e (puisquâ€™elle est dÃ©jÃ  payÃ©e). Le modÃ¨le de paiement Ã  lâ€™usage du cloud implique que les dÃ©cisions (ou non-dÃ©cisions) sont toujours Ã  venir : Ã  chaque instant on peut redimensionner, supprimer, â€¦ et câ€™est dâ€™autant plus important de le faire quâ€™ayant affaire Ã  des services managÃ©s,** le coÃ»t nâ€™inclut pas seulement le matÃ©riel** : on paie aussi Ã  lâ€™usage le service managÃ© (gestion de lâ€™infra physique, haute dispo, sauvegardes, patch management etc.). Ici, LA bonne pratique : **Ã©tiquetez** ğŸ·ï¸ vos ressources. Chaque ressource dÃ©ployÃ©e doit Ãªtre identifiÃ©e clairement par des *tags *qui permettront dâ€™identifier dans les rapports le projet, lâ€™Ã©quipe, le produit, la business unit, le processus mÃ©tier, etc. qui justifie lâ€™existence de la ressource. Les tags doivent expliquer 100% de vos coÃ»ts, hors ressources non-Ã©tiquetables comme le trafic rÃ©seau (qui peut aussi faire lâ€™objet dâ€™analyses si besoin via les flow logs). Il est possible de mettre en place des Â« politiques de tagging Â» pour garantir lâ€™application de ces tags, soit ex-post par un audit soit ex-ante en refusant la crÃ©ation de ressources non-Ã©tiquetÃ©es.

## 2. Utilisez Ã  fond les outils fournis par votre fournisseur

Rien que sur AWS, les outils sont nombreux : - les Tags et Tag policies au niveau de lâ€™organisation - le **Cost Explorer** et les Cost & Usage Reports, tableaux croisÃ©s dynamiques qui permettent un reporting facile sur les coÃ»ts - les recommandations de dimensionnement de **Compute Optimizer **et celles des Trusted Advisor pour les entreprises qui ont le niveau de support Business, qui permettent de ne pas sur-provisionner des ressources. - la gestion des budgets, permettant de suivre les coÃ»ts par Ã©quipe - la **dÃ©tection dâ€™anomalie**, au niveau de chaque compte, service ou Ã©tiquette - les **mÃ©triques de taux de couverture et dâ€™utilisation** des rÃ©servations de ressources.   Outre ces services disponibles sur Ã©tagÃ¨re, il est possible, [avec les Cloud Intelligence Dashboards](https://www.wellarchitectedlabs.com/cloud-intelligence-dashboards/), de dÃ©ployer facilement de la BI avancÃ©e pour rendre actionnable lâ€™information financiÃ¨re.

![Cloud Intelligence Dashboards, pour dÃ©passer le tableau croisÃ© dynamique du Cost Explorer](/images/blog/CID-300x220.png)

## 3. DÃ©finissez des politiques et automatisez

Le modÃ¨le de paiement Ã  lâ€™usage peut Ãªtre mis Ã  profit grÃ¢ce aux possibilitÃ©s dâ€™automatisation du cloud (tout peut se contrÃ´ler via API). Il est donc possible de dÃ©terminer des politiques qui seront effectivement mises en oeuvre sans effort aprÃ¨s un petit investissement initial, par ex. Â« *les ressources de test doivent Ãªtre coupÃ©es entre 22h et 8h, Ã  moins dâ€™Ãªtre taguÃ©es spÃ©cifiquement chaque semaine* Â» sera automatisÃ© par un processus quotidien dâ€™extinction des ressources et un processus hebdo de suppression des Ã©tiquettes de rÃ©tention.

## 4. Prenez vos dÃ©cisions de dimensionnement en s'appuyant sur des donnÃ©es

Sur le cloud, chaque service publie des mÃ©triques permettant dâ€™avoir une comprÃ©hension prÃ©cise de lâ€™utilisation rÃ©elle des ressources. Si le souhait dâ€™assurer un dÃ©marrage sans accroc dâ€™une nouvelle charge de travail peut amener Ã  prendre un coefficient de sÃ©curitÃ© important lors du prÃ©-dimensionnement (mieux : on peut grÃ¢ce Ã  des services Â« serverless Â» sâ€™Ã©pargner ce dimensionnement initial), **ces mÃ©triques peuvent Ãªtre exploitÃ©es aprÃ¨s quelques semaines de vie de lâ€™application pour Â« re-tailler Â»** lâ€™infrastructure au strict nÃ©cessaire.

![Un serveur de fichiers FSX pour NetApp ONTAP trÃ¨s sur-dimensionnÃ© / sous-utilisÃ©.](/images/blog/FSX-300x174.png)

Notez que pour les machines virtuelles, seules les mÃ©triques dâ€™hyperviseur (CPU, I/Os) sont activÃ©es par dÃ©faut (car lâ€™hÃ´te ne Â« sait pas Â» ce que la machine fait rÃ©ellement de la mÃ©moire ou de lâ€™espace disque qui lui sont allouÃ©s). Sur AWS, il est donc souhaitable **dâ€™installer lâ€™agent CloudWatch et de publier les mÃ©triques dâ€™instances (RAM, Disk) **qui sont alors prises en compte par Compute Optimizer pour fournir des recommandations pertinentes.

## 5. Une organisation adaptÃ©e au cloud

La caractÃ©ristique commune des organisations qui perdent inutilement de lâ€™argent sur le cloud est que **personne nâ€™y est responsable des coÃ»ts**. Il y a bien quelquâ€™un qui gÃ¨re le budget annuel (souvent un manager), mais il nâ€™est pas envisageable (ni souhaitable) quâ€™il soit associÃ© Ã  chaque choix de dimensionnement. Ces dÃ©cisions sont donc prises par les experts techniques : les DBA gÃ¨rent les bases de donnÃ©es, les SysOps gÃ¨rent les VMs, etc. et les dÃ©cisions sont prises trÃ¨s loin des centres de profits. Or, la principale [source de valeur du cloud (cf. mon article Ã  ce sujet)](https://www.linkedin.com/pulse/cloud-101-episode-1-quelle-est-la-vraie-valeur-ajout%2525C3%2525A9e-du%3FtrackingId=d7juZseZnBjP9elYjNTHrg%253D%253D/?trackingId=d7juZseZnBjP9elYjNTHrg%3D%3D) est la possibilitÃ© quâ€™il offre, **en abaissant les barriÃ¨res techniques, dâ€™aligner business et technique**. Et donc de constituer des Ã©quipes portant leur propre Â« P&L Â» (compte de rÃ©sultat) dâ€™infrastructure. Dans ce modÃ¨le, le DBA est un spÃ©cialiste qui apporte un conseil, de lâ€™analyse sur des problÃ©matiques difficiles, pas le type qui sâ€™occupe de faire fonctionner les bases de donnÃ©es en boÃ®te noire. La **formation est clÃ©** pour sensibiliser aux enjeux de coÃ»ts sur le cloud et orienter lâ€™Ã©quipe vers la conception dâ€™infrastructures pertinentes.

## 6. Des charges de travail adaptÃ©es au cloud

De plus, le fait dâ€™Ãªtre sur le cloud doit progressivement influer la conception mÃªme de vos applications, leur architecture, pour tirer le meilleur parti des services. Evitez dâ€™Ãªtre le prochain CTO qui fera un billet de blog Â« *pourquoi jâ€™ai quittÃ© le cloud Â»* (avec ğŸ¤¦ garanti de tous les experts cloud qui au fil de sa lecture rÃ©alisent le dÃ©sastre de mauvaise conception qui a menÃ© Ã  cette sortie). Vos **applications peuvent en particulier tirer parti en particulier de logiques de scalabilitÃ© horizontale** (par *autoscaling*i.e. on ajoute et on retire des noeuds de calcul en fonction de la charge rÃ©elle) plutÃ´t que verticale (on ajoute de la RAM, du CPU sur la/les machines qui portent lâ€™application). Elles peuvent aussi sâ€™appuyer sur **des services qui Â« scalent vers zÃ©ro Â»**(pas dâ€™usage, pas de coÃ»t) comme les Fonctions-as-a-Service (Lambda), les files ou bus dâ€™Ã©vÃ©nements managÃ©s (SQS, EventBridge) dont le modÃ¨le nâ€™est plus un paiement Ã  lâ€™heure mais Ã  lâ€™appel (au million dâ€™appel) dâ€™API. Plus proches de la prod (et plus conscientes des coÃ»ts), les Ã©quipes de dÃ©veloppement auront Ã  coeur de **rÃ©soudre les problÃ©matiques de performance **qui impactent significativement les coÃ»ts (par ex. cette requÃªte SQL exÃ©cutÃ©e une fois par jour qui provoque le sur-dimensionnement de la BDD).

## 7. Des revues rÃ©guliÃ¨res

Chez mon client, la principale source de coÃ»ts non-justifiÃ©e rÃ©sidait dans le volume dâ€™instantanÃ©s (snapshots) conservÃ©s.

![Une revue mensuelle aurait alertÃ© dÃ¨s juin 2023 sur le coÃ»t associÃ© Ã  ces sauvegardes](/images/blog/EBS-Snapshots-300x233.png)

Une revue rÃ©guliÃ¨re aurait permis de questionner lâ€™utilitÃ© de ces instantanÃ©s, et de dÃ©finir le cas Ã©chÃ©ant le meilleur stockage pour ceux-ci (il y a un ratio de 53 entre Glacier Deep Archive â€“ $0,00099 par Go.mois â€“ et le stockage en ligne des instantanÃ©s â€“ $0.053 par Go.mois). A minima, **une analyse Â« mois Ã  mois Â» doit Ãªtre menÃ©e sur les coÃ»ts **pour identifier et expliquer les principales variations. Ce travail nâ€™est pas nÃ©cessairement trÃ¨s important : il faut compter pour cela 2h de travail mensuel pour $5k/mois de coÃ»ts rÃ©currents. En complÃ©ment, l**es Well Architected Framework Reviews **sont lâ€™occasion dâ€™aborder cette question de lâ€™optimisation des coÃ»ts, parmi dâ€™autres (fiabilitÃ©, sÃ©curitÃ©, etc.). Un** rÃ´le dâ€™animateur FinOps **peut Ãªtre identifiÃ© au sein de lâ€™Ã©quipe pour faciliter lâ€™animation de ces revues ; veillez cependant Ã  ce que son existence ne soit pas dÃ©responsabilisante pour le reste de lâ€™Ã©quipe.

[TerraCloud](https://www.linkedin.com/company/terracloud/) peut vous aider Ã  **progresser dans la maÃ®trise** de votre infrastructure et de ses coÃ»ts, de lâ€™analyse FinOps ponctuelle Ã  la formation de vos Ã©quipes et lâ€™accompagnement pour la mise en place de bonnes pratiques pÃ©rennes.